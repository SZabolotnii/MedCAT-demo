# –Ü–Ω—Ç–µ–≥—Ä–∞—Ü—ñ—è –≤–ª–∞—Å–Ω–æ—ó –º–µ–¥–∏—á–Ω–æ—ó –æ–Ω—Ç–æ–ª–æ–≥—ñ—ó –≤ MedCAT –±–µ–∑ unsupervised training

## –í–ò–°–ù–û–í–û–ö: Unsupervised training –æ–ø—Ü—ñ–æ–Ω–∞–ª—å–Ω–∏–π, –∞–ª–µ –∑ –æ–±–º–µ–∂–µ–Ω–Ω—è–º–∏

MedCAT **–º–æ–∂–µ –ø–æ–≤–Ω–æ—Ü—ñ–Ω–Ω–æ –ø—Ä–∞—Ü—é–≤–∞—Ç–∏ –±–µ–∑ unsupervised training** –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—é—á–∏ dictionary-based –ø—ñ–¥—Ö—ñ–¥ –∑ –≤–ª–∞—Å–Ω–æ—é –æ–Ω—Ç–æ–ª–æ–≥—ñ—î—é. –°–∏—Å—Ç–µ–º–∞ –ø–æ—Ç—Ä–µ–±—É—î –ª–∏—à–µ CDB (Concept Database) —Ç–∞ spacy –º–æ–¥–µ–ª—å –¥–ª—è –±–∞–∑–æ–≤–æ–≥–æ —Ñ—É–Ω–∫—Ü—ñ–æ–Ω—É–≤–∞–Ω–Ω—è, –¥–æ—Å—è–≥–∞—é—á–∏ F1 ‚âà 0.638 —É –∫–ª—ñ–Ω—ñ—á–Ω–∏—Ö —Ç–µ–∫—Å—Ç–∞—Ö. –û—Å–Ω–æ–≤–Ω–µ –æ–±–º–µ–∂–µ–Ω–Ω—è ‚Äì **–≤—ñ–¥—Å—É—Ç–Ω—ñ—Å—Ç—å disambiguation** –¥–ª—è ambiguous concepts, —â–æ –ø—Ä–∏–∑–≤–æ–¥–∏—Ç—å –¥–æ –∑–Ω–∏–∂–µ–Ω–Ω—è —Ç–æ—á–Ω–æ—Å—Ç—ñ –Ω–∞ 20-25% –ø–æ—Ä—ñ–≤–Ω—è–Ω–æ –∑ –Ω–∞—Ç—Ä–µ–Ω–æ–≤–∞–Ω–∏–º–∏ –º–æ–¥–µ–ª—è–º–∏.

---

## 1. –ß–∏ –æ–±–æ–≤'—è–∑–∫–æ–≤–∏–π unsupervised training –¥–ª—è MedCAT?

### –û—Ñ—ñ—Ü—ñ–π–Ω–∞ –ø–æ–∑–∏—Ü—ñ—è: –û–ü–¶–Ü–û–ù–ê–õ–¨–ù–ò–ô, –∞–ª–µ –Ω–∞—Å—Ç—ñ–π–Ω–æ —Ä–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞–Ω–∏–π

**–ú—ñ–Ω—ñ–º–∞–ª—å–Ω—ñ –æ–±–æ–≤'—è–∑–∫–æ–≤—ñ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∏:**
- ‚úÖ **CDB (Concept Database)** ‚Äì —Å–ª–æ–≤–Ω–∏–∫ –ø–æ–Ω—è—Ç—å –∑ —Å–∏–Ω–æ–Ω—ñ–º–∞–º–∏
- ‚úÖ **Spacy –º–æ–¥–µ–ª—å** (en_core_web_md –∞–±–æ en_core_sci_md) ‚Äì –¥–ª—è —Ç–æ–∫–µ–Ω—ñ–∑–∞—Ü—ñ—ó/–ª–µ–º–∞—Ç–∏–∑–∞—Ü—ñ—ó
- ‚úÖ **Config** ‚Äì –∫–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ–π–Ω–∏–π –æ–±'—î–∫—Ç
- ‚ùå **Vocab** ‚Äì –æ–ø—Ü—ñ–æ–Ω–∞–ª—å–Ω–∏–π (–º–æ–∂–Ω–∞ vocab=None)
- ‚ùå **Context vectors** ‚Äì —Å—Ç–≤–æ—Ä—é—é—Ç—å—Å—è –õ–ò–®–ï —á–µ—Ä–µ–∑ unsupervised training

**–©–æ –ø—Ä–∞—Ü—é—î –ë–ï–ó unsupervised training:**
- Dictionary-based entity detection (expanding window algorithm)
- –†–æ–∑–ø—ñ–∑–Ω–∞–≤–∞–Ω–Ω—è –ø–æ–Ω—è—Ç—å –∑ —É–Ω—ñ–∫–∞–ª—å–Ω–∏–º–∏ –Ω–∞–∑–≤–∞–º–∏ (~95% UMLS concepts –º–∞—é—Ç—å —Ö–æ—á–∞ –± –æ–¥–Ω—É —É–Ω—ñ–∫–∞–ª—å–Ω—É –Ω–∞–∑–≤—É)
- Spell checking –±–∞–∑–æ–≤–æ–≥–æ —Ä—ñ–≤–Ω—è
- –¢–æ–∫–µ–Ω—ñ–∑–∞—Ü—ñ—è —Ç–∞ –ª–µ–º–∞—Ç–∏–∑–∞—Ü—ñ—è —á–µ—Ä–µ–∑ spacy
- –ü—Ä–∏–≤'—è–∑–∫–∞ (linking) –¥–æ –∫–æ–Ω—Ü–µ–ø—Ç—ñ–≤ –±–µ–∑ disambiguation

**–©–æ –ù–ï –ø—Ä–∞—Ü—é—î –±–µ–∑ training:**
- ‚ùå **Disambiguation ambiguous concepts** ‚Äì –Ω–µ –º–æ–∂–µ —Ä–æ–∑—Ä—ñ–∑–Ω–∏—Ç–∏ "HR" (Heart Rate vs Hazard Ratio)
- ‚ùå **Context-based linking** ‚Äì –Ω–µ–º–∞—î –ø–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω–æ—ó —Å—Ö–æ–∂–æ—Å—Ç—ñ
- ‚ùå **Confidence scoring** ‚Äì –æ—Ü—ñ–Ω–∫–∞ –¥–æ—Å—Ç–æ–≤—ñ—Ä–Ω–æ—Å—Ç—ñ –Ω–∞ –æ—Å–Ω–æ–≤—ñ –∫–æ–Ω—Ç–µ–∫—Å—Ç—É
- ‚ùå **Dynamic thresholding** ‚Äì –∞–¥–∞–ø—Ç–∏–≤–Ω—ñ –ø–æ—Ä–æ–≥–∏ –¥–ª—è —Ä—ñ–∑–Ω–∏—Ö –∫–æ–Ω—Ü–µ–ø—Ç—ñ–≤

### –ö—ñ–ª—å–∫—ñ—Å–Ω—ñ –ø–æ–∫–∞–∑–Ω–∏–∫–∏ –ø—Ä–æ–¥—É–∫—Ç–∏–≤–Ω–æ—Å—Ç—ñ

**Clinical Dataset (King's College Hospital):**
- –ë–µ–∑ training: F1 = **0.638** (¬±0.297 SD) 
- –ó MIMIC-III training: F1 = **0.840** (¬±0.109 SD)
- –ó domain-specific training: F1 = **0.889** (¬±0.078 SD)
- –ó supervised training: F1 = **0.947** (¬±0.044 SD)

**–†—ñ–∑–Ω–∏—Ü—è: –±–µ–∑ training –≤—Ç—Ä–∞—á–∞—î—Ç–µ 20-25% F1 score**

---

## 2. –í–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è –≥–æ—Ç–æ–≤–∏—Ö spacy –º–æ–¥–µ–ª–µ–π

### –Ø–∫ –ø—Ä–∞—Ü—é—î —ñ–Ω—Ç–µ–≥—Ä–∞—Ü—ñ—è spacy –∑ MedCAT

**–ê—Ä—Ö—ñ—Ç–µ–∫—Ç—É—Ä–∞ –≤–∑–∞—î–º–æ–¥—ñ—ó:**
```
Input Text
    ‚Üì
spaCy (en_core_web_md/en_core_sci_md)
    ‚Üí Tokenization (—Ä–æ–∑–±–∏—Ç—Ç—è –Ω–∞ —Ç–æ–∫–µ–Ω–∏)
    ‚Üí Lemmatization (–Ω–æ—Ä–º–∞–ª—ñ–∑–∞—Ü—ñ—è –¥–æ –±–∞–∑–æ–≤–æ—ó —Ñ–æ—Ä–º–∏)
    ‚Üí POS tagging (—á–∞—Å—Ç–∏–Ω–∏ –º–æ–≤–∏)
    ‚Üì
MedCAT Dictionary-based NER
    ‚Üí Concept detection (–ø–æ—à—É–∫ –ø–æ CDB)
    ‚Üí Spell checking (—è–∫—â–æ vocab —î)
    ‚Üì
MedCAT Linking
    ‚Üí Disambiguation (—è–∫—â–æ —î context vectors)
    ‚Üí Confidence scoring
```

**–í–∞–∂–ª–∏–≤–æ:** MedCAT **–ù–ï –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î** spacy NER –∫–æ–º–ø–æ–Ω–µ–Ω—Ç! –í—ñ–Ω –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î –ª–∏—à–µ preprocessing.

### –ü–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è en_core_web_md vs en_core_sci_md

| –•–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∞ | en_core_web_md | en_core_sci_md |
|----------------|----------------|----------------|
| **–¢—Ä–µ–Ω—É–≤–∞–ª—å–Ω—ñ –¥–∞–Ω—ñ** | –í–µ–±-—Ç–µ–∫—Å—Ç–∏ (–±–ª–æ–≥–∏, –Ω–æ–≤–∏–Ω–∏) | PubMed + MIMIC-III –∫–ª—ñ–Ω—ñ—á–Ω—ñ –∑–∞–ø–∏—Å–∏ |
| **Word vectors** | 300D GloVe, ~20k —É–Ω—ñ–∫–∞–ª—å–Ω–∏—Ö | 300D, —Ç—Ä–µ–Ω—É–≤–∞–ª–∏—Å—è –Ω–∞ –±—ñ–æ–º–µ–¥–∏—á–Ω–∏—Ö —Ç–µ–∫—Å—Ç–∞—Ö |
| **–ü—ñ–¥—Ç—Ä–∏–º–∫–∞** | –û—Ñ—ñ—Ü—ñ–π–Ω–∞ spaCy –ø—ñ–¥—Ç—Ä–∏–º–∫–∞ | scispaCy (Allen AI) |
| **–î–ª—è MedCAT** | –†–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞–Ω–æ –∑ v1.2+ | –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–≤–∞–ª–æ—Å—å —É —Å—Ç–∞—Ä–∏—Ö –≤–µ—Ä—Å—ñ—è—Ö |
| **–†—ñ–∑–Ω–∏—Ü—è** | **"Very little difference"** –∑–∞ —Å–ª–æ–≤–∞–º–∏ —Ä–æ–∑—Ä–æ–±–Ω–∏–∫—ñ–≤ MedCAT |

**–í–∏—Å–Ω–æ–≤–æ–∫ —Ä–æ–∑—Ä–æ–±–Ω–∏–∫—ñ–≤:** –î–ª—è MedCAT –≤–∏–±—ñ—Ä –º—ñ–∂ en_core_web_md —Ç–∞ en_core_sci_md –º–∞—î **–º—ñ–Ω—ñ–º–∞–ª—å–Ω–∏–π –≤–ø–ª–∏–≤**, –æ—Å–∫—ñ–ª—å–∫–∏ MedCAT –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î dictionary-based –ø—ñ–¥—Ö—ñ–¥, –∞ –Ω–µ spacy NER.

### –ß–∏ –ø–æ—Ç—Ä—ñ–±–µ–Ω –æ–∫—Ä–µ–º–∏–π Vocab –∫–æ–º–ø–æ–Ω–µ–Ω—Ç?

**–ö–æ—Ä–æ—Ç–∫–∞ –≤—ñ–¥–ø–æ–≤—ñ–¥—å: –ù–Ü, –º–æ–∂–Ω–∞ vocab=None**

**MedCAT Vocab vs spaCy vectors:**
- **MedCAT Vocab**: –û–∫—Ä–µ–º–∏–π –∫–æ–º–ø–æ–Ω–µ–Ω—Ç –∑ word embeddings –¥–ª—è context similarity
- **spaCy vectors**: –í–±—É–¥–æ–≤–∞–Ω—ñ –≤ –º–æ–¥–µ–ª—å, –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—é—Ç—å—Å—è –¥–ª—è preprocessing
- **–í–æ–Ω–∏ –ù–ï –≤–∑–∞—î–º–æ–∑–∞–º—ñ–Ω–Ω—ñ** ‚Äì —Ä—ñ–∑–Ω—ñ –ø—Ä–∏–∑–Ω–∞—á–µ–Ω–Ω—è

**–°—Ç–≤–æ—Ä–µ–Ω–Ω—è CAT –±–µ–∑ Vocab:**
```python
from medcat.cat import CAT
from medcat.cdb import CDB

cdb = CDB.load('path/to/cdb')
cat = CAT(cdb=cdb, config=cdb.config, vocab=None)  # ‚úÖ Vocab=None –ø—Ä–∞—Ü—é—î!
cat.spacy_cat.train = False  # –í–∏–º–∫–Ω—É—Ç–∏ training
```

**–©–æ –≤—Ç—Ä–∞—á–∞—î—Ç–µ –±–µ–∑ Vocab:**
- Spell checking –æ–±–º–µ–∂–µ–Ω–∏–π
- –ù–µ–º–∞—î domain-specific word embeddings
- –ù–µ –º–æ–∂–Ω–∞ —Ä–æ–±–∏—Ç–∏ unsupervised training

---

## 3. –°—Ç–≤–æ—Ä–µ–Ω–Ω—è working MedCAT –∑ –≤–ª–∞—Å–Ω–æ—é –æ–Ω—Ç–æ–ª–æ–≥—ñ—î—é –ë–ï–ó training

### –ö—Ä–æ–∫ 1: –ü—ñ–¥–≥–æ—Ç—É–≤–∞—Ç–∏ –æ–Ω—Ç–æ–ª–æ–≥—ñ—é —É CSV —Ñ–æ—Ä–º–∞—Ç—ñ

**–û–±–æ–≤'—è–∑–∫–æ–≤—ñ –∫–æ–ª–æ–Ω–∫–∏:**
- `cui` ‚Äì —É–Ω—ñ–∫–∞–ª—å–Ω–∏–π ID –∫–æ–Ω—Ü–µ–ø—Ç—É
- `name` ‚Äì –Ω–∞–∑–≤–∞ –∫–æ–Ω—Ü–µ–ø—Ç—É –∞–±–æ —Å–∏–Ω–æ–Ω—ñ–º

**–û–ø—Ü—ñ–æ–Ω–∞–ª—å–Ω—ñ –∫–æ–ª–æ–Ω–∫–∏:**
- `ontologies` ‚Äì –¥–∂–µ—Ä–µ–ª–æ (SNOMED, CUSTOM, —Ç–æ—â–æ)
- `name_status` ‚Äì 'P' (Preferred), 'A' (Automatic), 'N' (Not common)
- `type_ids` ‚Äì —Å–µ–º–∞–Ω—Ç–∏—á–Ω—ñ —Ç–∏–ø–∏ (TUI)
- `description` ‚Äì –æ–ø–∏—Å –∫–æ–Ω—Ü–µ–ø—Ç—É

**–ü—Ä–∏–∫–ª–∞–¥ CSV:**
```csv
cui,name,ontologies,name_status,type_ids,description
C001,Diabetes Mellitus,CUSTOM,P,T047,Metabolic disorder
C001,Diabetes,CUSTOM,A,T047,
C001,DM,CUSTOM,A,T047,
C002,Hypertension,CUSTOM,P,T047,High blood pressure
C002,HTN,CUSTOM,A,T047,
C002,High Blood Pressure,CUSTOM,A,T047,
C003,Kidney Failure,CUSTOM,P,T047,Renal insufficiency
C003,Renal Failure,CUSTOM,A,T047,
```

### –ö—Ä–æ–∫ 2: –°—Ç–≤–æ—Ä–∏—Ç–∏ CDB –∑ CSV

```python
from medcat.cdb_maker import CDBMaker
from medcat.config import Config

# –Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—è
config = Config()
maker = CDBMaker(config)

# –°—Ç–≤–æ—Ä–µ–Ω–Ω—è CDB –∑ CSV
cdb = maker.prepare_csvs(
    csv_paths=['my_ontology.csv'],
    full_build=False,  # False = —à–≤–∏–¥—à–µ, –º–µ–Ω—à–∏–π —Ä–æ–∑–º—ñ—Ä
    sep=',',
    encoding='utf-8'
)

# –ó–±–µ—Ä–µ–≥—Ç–∏ CDB
cdb.save('my_custom_cdb')
print(f"–°—Ç–≤–æ—Ä–µ–Ω–æ CDB –∑ {len(cdb.cui2names)} –∫–æ–Ω—Ü–µ–ø—Ç—ñ–≤")
```

### –ö—Ä–æ–∫ 3: –Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑—É–≤–∞—Ç–∏ CAT –±–µ–∑ training

```python
from medcat.cat import CAT
from medcat.cdb import CDB

# –í—Å—Ç–∞–Ω–æ–≤–∏—Ç–∏ spacy –º–æ–¥–µ–ª—å (—è–∫—â–æ —â–µ –Ω–µ –≤—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ)
# python -m spacy download en_core_web_md

# –ó–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ CDB
cdb = CDB.load('my_custom_cdb')

# –°—Ç–≤–æ—Ä–∏—Ç–∏ CAT –ë–ï–ó vocab (–Ω–µ–º–∞—î unsupervised training capability)
cat = CAT(
    cdb=cdb,
    config=cdb.config,
    vocab=None  # ‚úÖ –ù–µ–º–∞—î vocab = –Ω–µ–º–∞—î training
)

# –û–ë–û–í'–Ø–ó–ö–û–í–û: –≤–∏–º–∫–Ω—É—Ç–∏ training
cat.spacy_cat.train = False
```

### –ö—Ä–æ–∫ 4: –ù–∞–ª–∞—à—Ç—É–≤–∞—Ç–∏ config –¥–ª—è dictionary-only —Ä–µ–∂–∏–º—É

```python
# –í–∏–º–∫–Ω—É—Ç–∏ context similarity
cat.config.linking['always_calculate_similarity'] = False
cat.config.linking['similarity_threshold'] = 1.0  # Effectively disabled

# Rule-based preferences –¥–ª—è disambiguation
cat.config.linking['prefer_primary_name'] = 0.5  # –ü–µ—Ä–µ–≤–∞–≥–∞ primary names
cat.config.linking['prefer_frequent_concepts'] = 0.3  # –ß–∞—Å—Ç—ñ—à—ñ –∫–æ–Ω—Ü–µ–ø—Ç–∏

# NER –Ω–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è
cat.config.ner['min_name_len'] = 3  # –ú—ñ–Ω—ñ–º–∞–ª—å–Ω–∞ –¥–æ–≤–∂–∏–Ω–∞ –¥–ª—è detection
cat.config.ner['upper_case_limit_len'] = 4  # Uppercase –¥–ª—è –∫–æ—Ä–æ—Ç–∫–∏—Ö —Ç–µ—Ä–º—ñ–Ω—ñ–≤
cat.config.general['spell_check'] = True  # Spell checking
```

### –ö—Ä–æ–∫ 5: –í–∏–∫–æ—Ä–∏—Å—Ç–∞—Ç–∏ –¥–ª—è –∞–Ω–æ—Ç–∞—Ü—ñ—ó

```python
# –¢–µ—Å—Ç–æ–≤–∏–π —Ç–µ–∫—Å—Ç
text = """
Patient with type 2 diabetes and hypertension. 
History of renal failure. Prescribed medications for HTN.
"""

# –ê–Ω–æ—Ç–∞—Ü—ñ—è –ë–ï–ó training
entities = cat.get_entities(text)

# –í–∏–≤–µ—Å—Ç–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏
for entity_id, entity in entities['entities'].items():
    print(f"–ó–Ω–∞–π–¥–µ–Ω–æ: '{entity['source_value']}' ‚Üí "
          f"{entity['pretty_name']} (CUI: {entity['cui']}, "
          f"confidence: {entity['acc']:.2f})")
```

### –ö—Ä–æ–∫ 6: –ó–±–µ—Ä–µ–≥—Ç–∏ –º–æ–¥–µ–ª—å

```python
# –ó–±–µ—Ä–µ–≥—Ç–∏ —è–∫ model pack
cat.create_model_pack(
    save_dir_path='my_medcat_model',
    model_pack_name='custom_medical_model',
    cdb_format='dill'
)

print("‚úÖ –ú–æ–¥–µ–ª—å –∑–±–µ—Ä–µ–∂–µ–Ω–∞ —ñ –≥–æ—Ç–æ–≤–∞ –¥–æ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è!")
```

### –ü–æ–≤–Ω–∏–π —Ä–æ–±–æ—á–∏–π –ø—Ä–∏–∫–ª–∞–¥ (minimal viable code)

```python
# –ú–Ü–ù–Ü–ú–ê–õ–¨–ù–ò–ô WORKING –ü–†–ò–ö–õ–ê–î
from medcat.cdb_maker import CDBMaker
from medcat.config import Config
from medcat.cat import CAT
from medcat.cdb import CDB

# 1. –°—Ç–≤–æ—Ä–∏—Ç–∏ CSV –∑ –∫–æ–Ω—Ü–µ–ø—Ç–∞–º–∏
import pandas as pd

ontology = pd.DataFrame({
    'cui': ['C001', 'C001', 'C002', 'C003'],
    'name': ['Diabetes Mellitus', 'Diabetes', 'Hypertension', 'Kidney Failure'],
    'name_status': ['P', 'A', 'P', 'P']
})
ontology.to_csv('simple_ontology.csv', index=False)

# 2. –°—Ç–≤–æ—Ä–∏—Ç–∏ CDB
config = Config()
maker = CDBMaker(config)
cdb = maker.prepare_csvs(['simple_ontology.csv'], full_build=False)
cdb.save('simple_cdb')

# 3. –Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑—É–≤–∞—Ç–∏ CAT (–ë–ï–ó training)
cdb = CDB.load('simple_cdb')
cat = CAT(cdb=cdb, config=cdb.config, vocab=None)
cat.spacy_cat.train = False

# 4. –í–∏–∫–æ—Ä–∏—Å—Ç–∞—Ç–∏
text = "Patient has diabetes and hypertension"
entities = cat.get_entities(text)
for e in entities['entities'].values():
    print(f"{e['source_value']} ‚Üí {e['cui']}")

# ‚úÖ –ü–†–ê–¶–Æ–Ñ –ë–ï–ó UNSUPERVISED TRAINING!
```

---

## 4. –ö–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—è –¥–ª—è —Ä–æ–±–æ—Ç–∏ –±–µ–∑ context vectors

### –ü–∞—Ä–∞–º–µ—Ç—Ä–∏ –¥–ª—è –≤–∏–º–∫–Ω–µ–Ω–Ω—è training –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ñ–≤

```python
from medcat.config import Config

config = Config()

# === LINKING CONFIGURATION ===
# –û—Å–Ω–æ–≤–Ω—ñ –ø–∞—Ä–∞–º–µ—Ç—Ä–∏ –¥–ª—è dictionary-only mode
config.linking['train'] = False  # –í–∏–º–∫–Ω—É—Ç–∏ training
config.linking['always_calculate_similarity'] = False  # –ë–µ–∑ context similarity
config.linking['calculate_dynamic_threshold'] = False  # –ë–µ–∑ dynamic thresholds
config.linking['similarity_threshold'] = 1.0  # Effectively disable
config.linking['filter_before_disamb'] = False

# Rule-based disambiguation preferences
config.linking['prefer_primary_name'] = 0.5  # 0-1, higher = stronger preference
config.linking['prefer_frequent_concepts'] = 0.3  # Prefer more frequent concepts

# Context vectors (set to empty to disable)
config.linking['context_vector_sizes'] = {}  # –ü–æ—Ä–æ–∂–Ω—ñ–π dict = disabled
config.linking['context_vector_weights'] = {}  # –ü–æ—Ä–æ–∂–Ω—ñ–π dict = disabled

# === NER CONFIGURATION ===
config.ner['min_name_len'] = 3  # –ú—ñ–Ω—ñ–º–∞–ª—å–Ω–∞ –¥–æ–≤–∂–∏–Ω–∞ detection
config.ner['upper_case_limit_len'] = 4  # Uppercase –¥–ª—è –∫–æ—Ä–æ—Ç–∫–∏—Ö —Ç–µ—Ä–º—ñ–Ω—ñ–≤
config.ner['check_upper_case_names'] = True  # –ü–µ—Ä–µ–≤—ñ—Ä—è—Ç–∏ uppercase
config.ner['try_reverse_word_order'] = False  # –ó–≤–æ—Ä–æ—Ç–Ω—ñ–π –ø–æ—Ä—è–¥–æ–∫ —Å–ª—ñ–≤

# === GENERAL CONFIGURATION ===
config.general['spell_check'] = True  # Spell checking (–ø—Ä–∞—Ü—é—î –±–µ–∑ vocab)
config.general['spell_check_len_limit'] = 7  # Min length –¥–ª—è spell check
config.general['train'] = False  # –í–ê–ñ–õ–ò–í–û: disable training globally
config.general['spacy_disabled_components'] = [
    'ner', 'parser', 'vectors', 'textcat'  # –í–∏–º–∫–Ω—É—Ç–∏ –Ω–µ–ø–æ—Ç—Ä—ñ–±–Ω—ñ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∏
]

# === PREPROCESSING ===
config.preprocessing['skip_stopwords'] = False  # Keep stopwords (–º–µ–¥–∏—á–Ω—ñ —Ç–µ—Ä–º—ñ–Ω–∏)
config.preprocessing['min_len_normalize'] = 5
```

### –Ø–∫ –ø—Ä–∞—Ü—é—î linking –±–µ–∑ context similarity

**Dictionary-based disambiguation –∞–ª–≥–æ—Ä–∏—Ç–º:**

1. **Unique name matching:**
   - –Ø–∫—â–æ –≤–∏—è–≤–ª–µ–Ω–∞ –Ω–∞–∑–≤–∞ –≤—ñ–¥–ø–æ–≤—ñ–¥–∞—î –ª–∏—à–µ –û–î–ù–û–ú–£ CUI ‚Üí –ø—Ä—è–º–µ –ø—Ä–∏–≤'—è–∑—É–≤–∞–Ω–Ω—è
   - ~95% UMLS –∫–æ–Ω—Ü–µ–ø—Ç—ñ–≤ –º–∞—é—Ç—å —Ö–æ—á–∞ –± –æ–¥–Ω—É —É–Ω—ñ–∫–∞–ª—å–Ω—É –Ω–∞–∑–≤—É

2. **Ambiguous name resolution (rule-based):**
   –ö–æ–ª–∏ –æ–¥–Ω–∞ –Ω–∞–∑–≤–∞ –≤—ñ–¥–ø–æ–≤—ñ–¥–∞—î –∫—ñ–ª—å–∫–æ–º CUI, –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—é—Ç—å—Å—è:
   
   - **Primary name preference** (prefer_primary_name):
     - –ö–æ–Ω—Ü–µ–ø—Ç–∏, –¥–µ detection —î primary name, –æ—Ç—Ä–∏–º—É—é—Ç—å –ø–µ—Ä–µ–≤–∞–≥—É
   
   - **Concept frequency** (prefer_frequent_concepts):
     - –ß–∞—Å—Ç—ñ—à—ñ –∫–æ–Ω—Ü–µ–ø—Ç–∏ (–∑–∞ cui_count_train) –º–∞—é—Ç—å –ø–µ—Ä–µ–≤–∞–≥—É
   
   - **Name status priority:**
     - P = Preferred (–Ω–∞–π–≤–∏—â–∞ –ø—Ä—ñ–æ—Ä–∏—Ç–µ—Ç)
     - A = Automatic (—Å–µ—Ä–µ–¥–Ω—ñ–π)
     - N = Not common (–Ω–∞–π–Ω–∏–∂—á–∏–π)

3. **Default behavior:**
   - –Ø–∫—â–æ –Ω–µ–º–∞—î —á—ñ—Ç–∫–∏—Ö —Å–∏–≥–Ω–∞–ª—ñ–≤ ‚Üí –≤–∏–±–∏—Ä–∞—î—Ç—å—Å—è –ø–µ—Ä—à–µ/–Ω–∞–π—á–∞—Å—Ç—ñ—à–µ –∑—ñ—Å—Ç–∞–≤–ª–µ–Ω–Ω—è
   - –ê–±–æ –ø–æ–≤–µ—Ä—Ç–∞—î—Ç—å—Å—è —Å–ø–∏—Å–æ–∫ –≤—Å—ñ—Ö candidates

**–û–±–º–µ–∂–µ–Ω–Ω—è –±–µ–∑ context similarity:**
- –ù–µ –º–æ–∂–µ —Ä–æ–∑—Ä—ñ–∑–Ω–∏—Ç–∏ "MS" –≤ "patient has MS" (Multiple Sclerosis vs Mitral Stenosis)
- –ù–µ –º–æ–∂–µ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞—Ç–∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç "history of MS" vs "diagnosed with MS"
- ~40% –º–µ–¥–∏—á–Ω–∏—Ö –∫–æ–Ω—Ü–µ–ø—Ç—ñ–≤ —î ambiguous ‚Äì —Ü–µ –∫—Ä–∏—Ç–∏—á–Ω–µ –æ–±–º–µ–∂–µ–Ω–Ω—è

---

## 5. –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ñ –ø—ñ–¥—Ö–æ–¥–∏ –±–µ–∑ –≤–µ–ª–∏–∫–∏—Ö –æ–±—Å—è–≥—ñ–≤ –¥–∞–Ω–∏—Ö

### –í–∞—Ä—ñ–∞–Ω—Ç 1: –í–∏–∫–æ—Ä–∏—Å—Ç–∞—Ç–∏ pretrained MedCAT –º–æ–¥–µ–ª—ñ (–†–ï–ö–û–ú–ï–ù–î–û–í–ê–ù–û)

**–î–æ—Å—Ç—É–ø–Ω—ñ –ø—É–±–ª—ñ—á–Ω—ñ –º–æ–¥–µ–ª—ñ:**
- **UMLS Full** ‚Äì 4M+ –∫–æ–Ω—Ü–µ–ø—Ç—ñ–≤, trained –Ω–∞ MIMIC-III
- **UMLS Small** ‚Äì Disorders, symptoms, medications subset
- **SNOMED International** ‚Äì –ü–æ–≤–Ω–∏–π SNOMED-CT

**–Ø–∫ –æ—Ç—Ä–∏–º–∞—Ç–∏:**
1. –û—Ç—Ä–∏–º–∞—Ç–∏ UMLS license (–±–µ–∑–∫–æ—à—Ç–æ–≤–Ω–æ –¥–ª—è research): https://uts.nlm.nih.gov/
2. –ó–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ –º–æ–¥–µ–ª—å: https://medcat.sites.er.kcl.ac.uk/auth-callback
3. –í–∏–∫–æ—Ä–∏—Å—Ç–∞—Ç–∏:

```python
from medcat.cat import CAT

# –ó–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ pretrained –º–æ–¥–µ–ª—å
cat = CAT.load_model_pack('umls_small_model.zip')

# ‚úÖ –ü—Ä–∞—Ü—é—î –æ–¥—Ä–∞–∑—É –∑ F1 ‚âà 0.84, –ë–ï–ó –¥–æ–¥–∞—Ç–∫–æ–≤–æ–≥–æ training!
entities = cat.get_entities(text)
```

**–ü–µ—Ä–µ–≤–∞–≥–∏:**
- F1 = 0.840 (–∑–∞–º—ñ—Å—Ç—å 0.638 –±–µ–∑ training)
- –í–∂–µ –Ω–∞—Ç—Ä–µ–Ω–æ–≤–∞–Ω–æ –Ω–∞ MIMIC-III (2.4M –∫–ª—ñ–Ω—ñ—á–Ω–∏—Ö –∑–∞–ø–∏—Å—ñ–≤)
- Disambiguation –ø—Ä–∞—Ü—é—î "out of the box"
- –ù–µ–º–∞—î –ø–æ—Ç—Ä–µ–±–∏ –≤ –≤–ª–∞—Å–Ω–∏—Ö –¥–∞–Ω–∏—Ö

### –í–∞—Ä—ñ–∞–Ω—Ç 2: –í–∏–∫–æ—Ä–∏—Å—Ç–∞—Ç–∏ pretrained medical embeddings

**BioWordVec (NCBI):**
```python
# –ó–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ –∑ GitHub: ncbi-nlp/BioWordVec
# 2.3M —Å–ª—ñ–≤, 200 dimensions, trained –Ω–∞ PubMed + MeSH

from gensim.models import KeyedVectors
bio_embeddings = KeyedVectors.load_word2vec_format('BioWordVec.bin', binary=True)

# –Ü–Ω—Ç–µ–≥—Ä—É–≤–∞—Ç–∏ –∑ MedCAT —è–∫ vocab embeddings
# (–∫–æ–Ω–≤–µ—Ä—Ç—É–≤–∞—Ç–∏ —Ñ–æ—Ä–º–∞—Ç ‚Üí MedCAT vocab.dat)
```

**Bio_ClinicalBERT (Emily Alsentzer):**
```python
from transformers import AutoTokenizer, AutoModel

tokenizer = AutoTokenizer.from_pretrained("emilyalsentzer/Bio_ClinicalBERT")
model = AutoModel.from_pretrained("emilyalsentzer/Bio_ClinicalBERT")

# Trained –Ω–∞ MIMIC-III (880M words), initialized from BioBERT
# –ú–æ–∂–Ω–∞ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞—Ç–∏ –¥–ª—è creating context embeddings
```

### –í–∞—Ä—ñ–∞–Ω—Ç 3: scispaCy –∑ pretrained NER –º–æ–¥–µ–ª—è–º–∏

**–ì–æ—Ç–æ–≤—ñ –º–æ–¥–µ–ª—ñ –ë–ï–ó training:**
```python
import spacy
import scispacy

# –†—ñ–∑–Ω—ñ pretrained –º–æ–¥–µ–ª—ñ:
# en_ner_bc5cdr_md - Drugs, chemicals, diseases
# en_ner_bionlp13cg_md - Anatomical entities, cell types
# en_core_sci_md - General biomedical (785k vocab)

nlp = spacy.load("en_ner_bc5cdr_md")
doc = nlp("Patient with diabetes and hypertension")

for ent in doc.ents:
    print(f"{ent.text} ‚Üí {ent.label_}")

# ‚úÖ F1 ‚âà 0.60-0.65 –±–µ–∑ –¥–æ–¥–∞—Ç–∫–æ–≤–æ–≥–æ training
```

**Entity Linking –∑ UMLS:**
```python
from scispacy.linking import EntityLinker

nlp.add_pipe("scispacy_linker", config={"linker_name": "umls"})
doc = nlp(text)

for ent in doc.ents:
    for umls_ent in ent._.kb_ents:
        print(f"{ent.text} ‚Üí UMLS CUI: {umls_ent[0]}")
```

### –í–∞—Ä—ñ–∞–Ω—Ç 4: Zero-shot —Ç–∞ Few-shot –ø—ñ–¥—Ö–æ–¥–∏

**ProdicusII/ZeroShotBioNER (Hugging Face):**
```python
from transformers import AutoTokenizer, BertForTokenClassification

model = BertForTokenClassification.from_pretrained("ProdicusII/ZeroShotBioNER")

# Zero-shot: F1 = 35%
# 10-shot: F1 = 70%
# 100-shot: F1 = 80%
```

**LLM-based (GPT-4, Claude):**
```python
import openai

prompt = """
Extract medical entities from this text:
"Patient has diabetes and hypertension"

Return as JSON with entity type and text.
"""

# Zero-shot: F1 ‚âà 0.87 –¥–ª—è medications
# Few-shot (5-10 examples): F1 ‚âà 0.94
```

### –í–∞—Ä—ñ–∞–Ω—Ç 5: Transfer Learning –∑ MedCAT

**–ê–¥–∞–ø—Ç—É–≤–∞—Ç–∏ pretrained –º–æ–¥–µ–ª—å –¥–æ –≤–ª–∞—Å–Ω–æ—ó –æ–Ω—Ç–æ–ª–æ–≥—ñ—ó:**

```python
from medcat.cat import CAT
from medcat.cdb import CDB

# 1. –ó–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ pretrained –º–æ–¥–µ–ª—å
cat = CAT.load_model_pack('umls_small_model.zip')

# 2. –î–æ–¥–∞—Ç–∏ –≤–ª–∞—Å–Ω—ñ –∫–æ–Ω—Ü–µ–ø—Ç–∏
from medcat.utils.prepare_cdb import PrepareCDB
preparator = PrepareCDB(vocab=cat.vocab)
cat.cdb = preparator.prepare_csvs(['my_additional_concepts.csv'])

# 3. –û–ü–¶–Ü–û–ù–ê–õ–¨–ù–û: –ö–æ—Ä–æ—Ç–∫–∏–π self-supervised training –Ω–∞ –≤–∞—à–æ–º—É –∫–æ—Ä–ø—É—Å—ñ
# (—è–∫—â–æ —î 10K+ –¥–æ–∫—É–º–µ–Ω—Ç—ñ–≤, –º–æ–∂–Ω–∞ –ø–æ–∫—Ä–∞—â–∏—Ç–∏ –Ω–∞ 5-10% F1)
cat.train = True
for doc in your_small_corpus[:10000]:  # –ù–∞–≤—ñ—Ç—å 10K docs –¥–æ–ø–æ–º–∞–≥–∞—î
    _ = cat(doc)
cat.train = False

# 4. –ó–±–µ—Ä–µ–≥—Ç–∏
cat.create_model_pack('adapted_model.zip')
```

**–ü–µ—Ä–µ–≤–∞–≥–∏ transfer learning:**
- –ü–æ—á–∏–Ω–∞—î—Ç–µ –∑ F1 = 0.84 (pretrained)
- –î–æ–¥–∞—î—Ç–µ –≤–ª–∞—Å–Ω—ñ –∫–æ–Ω—Ü–µ–ø—Ç–∏
- –ú—ñ–Ω—ñ–º–∞–ª—å–Ω–∏–π self-supervised training (+0.05-0.10 F1)
- –ö—ñ–Ω—Ü–µ–≤–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç: F1 ‚âà 0.89 –∑ –º—ñ–Ω—ñ–º–∞–ª—å–Ω–∏–º–∏ –∑—É—Å–∏–ª–ª—è–º–∏

---

## 6. –ü–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è –ø—Ä–æ–¥—É–∫—Ç–∏–≤–Ω–æ—Å—Ç—ñ —Ä—ñ–∑–Ω–∏—Ö –ø—ñ–¥—Ö–æ–¥—ñ–≤

### Performance Benchmarks

| –ü—ñ–¥—Ö—ñ–¥ | F1 Score | Precision | Recall | Training Data Needed | Disambiguation |
|--------|----------|-----------|--------|---------------------|----------------|
| **MedCAT –±–µ–∑ training** | 0.638 | 0.60-0.65 | 0.60-0.65 | 0 | ‚ùå –ù–µ –ø—Ä–∞—Ü—é—î |
| **MedCAT + pretrained (MIMIC-III)** | **0.840** | 0.82-0.85 | 0.82-0.85 | 0 (use pretrained) | ‚úÖ –ü—Ä–∞—Ü—é—î |
| **MedCAT + domain training** | **0.889** | 0.87-0.90 | 0.87-0.90 | 10K-100K docs (unsupervised) | ‚úÖ‚úÖ –ö—Ä–∞—â–µ |
| **MedCAT + supervised (500 ex)** | **0.926** | 0.91-0.94 | 0.91-0.94 | 500 annotations | ‚úÖ‚úÖ‚úÖ –î—É–∂–µ –¥–æ–±—Ä–µ |
| **scispaCy (en_ner_bc5cdr_md)** | 0.60-0.65 | 0.58-0.63 | 0.60-0.68 | 0 (pretrained) | –û–±–º–µ–∂–µ–Ω–æ |
| **MetaMap (UMLS dictionary)** | 0.63-0.69 | 0.30-0.75 | 0.46-0.64 | 0 | Rule-based |
| **cTAKES** | 0.60-0.65 | 0.28-0.57 | 0.13-0.64 | 0 | Rule-based |
| **Zero-shot (ZeroShotBioNER)** | 0.35 | –Ω/–¥ | –Ω/–¥ | 0 | –Ω/–¥ |
| **Few-shot (100 examples)** | 0.80 | –Ω/–¥ | –Ω/–¥ | 100 annotations | –Ω/–¥ |
| **GPT-4 zero-shot (medications)** | 0.87 | –Ω/–¥ | –Ω/–¥ | 0 (prompt only) | ‚úÖ |

### Trade-offs —Ä—ñ–∑–Ω–∏—Ö –ø—ñ–¥—Ö–æ–¥—ñ–≤

**Dictionary-only MedCAT (–±–µ–∑ training):**
- ‚úÖ Pros: Zero training, immediate deployment, simple
- ‚ùå Cons: F1 loss 20-25%, no disambiguation, high FP rate
- üéØ Use case: Proof-of-concept, prototyping (<1 week)

**Pretrained MedCAT:**
- ‚úÖ Pros: Best F1/effort ratio, disambiguation works, ready in minutes
- ‚ùå Cons: Requires UMLS license, may not cover custom entities
- üéØ Use case: Production systems, standard clinical concepts

**scispaCy:**
- ‚úÖ Pros: MIT license, no restrictions, easy to use
- ‚ùå Cons: Lower F1, limited entity types, no custom ontology support
- üéØ Use case: Research, open-source projects, quick prototyping

**Zero-shot LLMs:**
- ‚úÖ Pros: No training data, flexible, good for custom entities
- ‚ùå Cons: API costs, latency, hallucinations, lower F1
- üéØ Use case: Rare entities, exploratory analysis, low volume

---

## 7. –ö–æ–ª–∏ –¥—ñ–π—Å–Ω–æ –ø–æ—Ç—Ä—ñ–±–µ–Ω unsupervised training?

### ‚úÖ Unsupervised training –û–ë–û–í'–Ø–ó–ö–û–í–ò–ô:

**1. –í–∏—Å–æ–∫–∞ ambiguity (–±–∞–≥–∞—Ç–æ –±–∞–≥–∞—Ç–æ–∑–Ω–∞—á–Ω–∏—Ö —Ç–µ—Ä–º—ñ–Ω—ñ–≤):**
- –ö–ª—ñ–Ω—ñ—á–Ω—ñ –∑–∞–ø–∏—Å–∏ –∑ –∞–±—Ä–µ–≤—ñ–∞—Ç—É—Ä–∞–º–∏ (MS, MI, HR, OD, —Ç–æ—â–æ)
- –í–µ–ª–∏–∫—ñ —Å–ª–æ–≤–Ω–∏–∫–∏ (UMLS 4M+, SNOMED 350K+ concepts)
- ~40% –º–µ–¥–∏—á–Ω–∏—Ö –∫–æ–Ω—Ü–µ–ø—Ç—ñ–≤ —î ambiguous

**2. –ö—Ä–∏—Ç–∏—á–Ω—ñ –∑–∞—Å—Ç–æ—Å—É–≤–∞–Ω–Ω—è:**
- Clinical decision support systems
- –ê–≤—Ç–æ–º–∞—Ç–∏—á–Ω–µ –∫–æ–¥—É–≤–∞–Ω–Ω—è (ICD-10, billing)
- Clinical trial recruitment
- –ë—É–¥—å-—è–∫—ñ high-stakes applications

**3. Domain-specific –∫–æ—Ä–ø—É—Å–∏:**
- –°–ø–µ—Ü—ñ–∞–ª—ñ–∑–æ–≤–∞–Ω—ñ –º–µ–¥–∏—á–Ω—ñ –¥–æ–º–µ–Ω–∏ (–æ–Ω–∫–æ–ª–æ–≥—ñ—è, –ø—Å–∏—Ö—ñ–∞—Ç—Ä—ñ—è)
- –†—ñ–∑–Ω—ñ —Å–∏—Å—Ç–µ–º–∏ EHR (Epic, Cerner, —Ä—ñ–∑–Ω—ñ –∫—Ä–∞—ó–Ω–∏)
- –ü–æ–∫—Ä–∞—â–µ–Ω–Ω—è F1 –Ω–∞ 5-10% –ø–æ—Ä—ñ–≤–Ω—è–Ω–æ –∑ –∑–∞–≥–∞–ª—å–Ω–æ—é –º–æ–¥–µ–ª–ª—é

**4. –ü–æ—Ç—Ä–µ–±–∞ –≤ –≤–∏—Å–æ–∫—ñ–π —Ç–æ—á–Ω–æ—Å—Ç—ñ:**
- Production deployments –¥–µ –ø–æ—Ç—Ä—ñ–±–µ–Ω F1 > 0.85
- –ú–∞—Å—à—Ç–∞–±–Ω—ñ –ø—Ä–æ–µ–∫—Ç–∏ (>100K –¥–æ–∫—É–º–µ–Ω—Ç—ñ–≤)

### ‚ùå Unsupervised training –û–ü–¶–Ü–û–ù–ê–õ–¨–ù–ò–ô:

**1. Proof-of-concept / Prototyping:**
- –ü–æ—á–∞—Ç–∫–æ–≤–µ —Ç–µ—Å—Ç—É–≤–∞–Ω–Ω—è feasibility
- –ö–æ—Ä–æ—Ç–∫—ñ –ø—Ä–æ–µ–∫—Ç–∏ (<1-2 —Ç–∏–∂–Ω—ñ)
- F1 ‚âà 0.638 –¥–æ—Å—Ç–∞—Ç–Ω—å–æ –¥–ª—è exploration

**2. –í–∏—Å–æ–∫–æ –∫—É—Ä–∞—Ç–æ—Ä–∞–Ω—ñ –Ω–µ–≤–µ–ª–∏–∫—ñ —Å–ª–æ–≤–Ω–∏–∫–∏:**
- Custom CDB –∑ –º—ñ–Ω—ñ–º–∞–ª—å–Ω–æ—é ambiguity
- –ü–µ—Ä–µ–≤–∞–∂–Ω–æ —É–Ω—ñ–∫–∞–ª—å–Ω—ñ –Ω–∞–∑–≤–∏ –∫–æ–Ω—Ü–µ–ø—Ç—ñ–≤
- –û–±–º–µ–∂–µ–Ω–∏–π vocabulary (—Å–æ—Ç–Ω—ñ –∫–æ–Ω—Ü–µ–ø—Ç—ñ–≤)
- **–ú–æ–∂–µ –¥–æ—Å—è–≥—Ç–∏ F1 ‚âà 0.75-0.80 –±–µ–∑ training**

**3. –ù–µ–∫—Ä–∏—Ç–∏—á–Ω—ñ –∑–∞–≤–¥–∞–Ω–Ω—è:**
- Research data exploration
- –ü–æ–ø–µ—Ä–µ–¥–Ω—è —ñ–¥–µ–Ω—Ç–∏—Ñ—ñ–∫–∞—Ü—ñ—è trends
- –°—Ç–∞—Ç–∏—Å—Ç–∏—á–Ω—ñ –æ–≥–ª—è–¥–∏ –¥–µ precision –º–µ–Ω—à –∫—Ä–∏—Ç–∏—á–Ω–∞

**4. –Ñ –¥–æ—Å—Ç—É–ø –¥–æ pretrained –º–æ–¥–µ–ª–µ–π:**
- –Ø–∫—â–æ –º–æ–∂–µ—Ç–µ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞—Ç–∏ UMLS/SNOMED pretrained
- Transfer learning –≤–∏—Ä—ñ—à—É—î –±—ñ–ª—å—à—ñ—Å—Ç—å –ø—Ä–æ–±–ª–µ–º
- F1 = 0.84 "out of the box"

### –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ—ó –∑–∞ use cases

| Use Case | Dictionary-only | Pretrained | Domain Training | Supervised |
|----------|----------------|-----------|-----------------|------------|
| **R\u0026D prototype** | ‚úÖ –î–æ—Å—Ç–∞—Ç–Ω—å–æ | üü° –ö—Ä–∞—â–µ | ‚ùå Overkill | ‚ùå Overkill |
| **Custom rare entities** | üü° –û–±–º–µ–∂–µ–Ω–æ | ‚ùå –ù–µ –ø–æ–∫—Ä–∏–≤–∞—î | ‚úÖ –ü–æ—Ç—Ä—ñ–±–Ω–æ | ‚úÖ –ù–∞–π–∫—Ä–∞—â–µ |
| **Clinical production** | ‚ùå –ù–µ–¥–æ—Å—Ç–∞—Ç–Ω—å–æ | ‚úÖ Good start | ‚úÖ –†–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞–Ω–æ | ‚úÖ Optimal |
| **Standard UMLS concepts** | üü° –ë–∞–∑–æ–≤–æ | ‚úÖ‚úÖ –Ü–¥–µ–∞–ª—å–Ω–æ | üü° Nice to have | üü° Optional |
| **Exploratory analysis** | ‚úÖ OK | ‚úÖ –ö—Ä–∞—â–µ | üü° Optional | ‚ùå Overkill |

---

## 8. Best Practices —Ç–∞ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ—ó

### –û–ø—Ç–∏–º–∞–ª—å–Ω–∞ —Å—Ç—Ä–∞—Ç–µ–≥—ñ—è –¥–ª—è —Ä—ñ–∑–Ω–∏—Ö —Å—Ü–µ–Ω–∞—Ä—ñ—ó–≤

**–°—Ü–µ–Ω–∞—Ä—ñ–π –ê: –®–≤–∏–¥–∫–∏–π –ø—Ä–æ—Ç–æ—Ç–∏–ø –∑ –≤–ª–∞—Å–Ω–æ—é –æ–Ω—Ç–æ–ª–æ–≥—ñ—î—é**
```python
# 1. –°—Ç–≤–æ—Ä–∏—Ç–∏ CSV –∑ –≤–∞—à–∏–º–∏ –∫–æ–Ω—Ü–µ–ø—Ç–∞–º–∏ (2-4 –≥–æ–¥–∏–Ω–∏)
# 2. –ü–æ–±—É–¥—É–≤–∞—Ç–∏ CDB (5-30 —Ö–≤–∏–ª–∏–Ω)
from medcat.cdb_maker import CDBMaker
cdb = CDBMaker(config).prepare_csvs(['ontology.csv'], full_build=False)

# 3. –Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑—É–≤–∞—Ç–∏ CAT –±–µ–∑ training (1 —Ö–≤–∏–ª–∏–Ω–∞)
cat = CAT(cdb=cdb, config=cdb.config, vocab=None)
cat.spacy_cat.train = False

# ‚úÖ –ì–æ—Ç–æ–≤–æ –∑–∞ <1 –¥–µ–Ω—å, F1 ‚âà 0.60-0.70
```

**–°—Ü–µ–Ω–∞—Ä—ñ–π –ë: Production –∑ standard medical concepts**
```python
# 1. –û—Ç—Ä–∏–º–∞—Ç–∏ UMLS license (1-2 –¥–Ω—ñ waiting)
# 2. –ó–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ pretrained –º–æ–¥–µ–ª—å (30 —Ö–≤–∏–ª–∏–Ω)
cat = CAT.load_model_pack('umls_small_model.zip')

# 3. –î–æ–¥–∞—Ç–∏ –≤–ª–∞—Å–Ω—ñ –∫–æ–Ω—Ü–µ–ø—Ç–∏ –¥–æ CDB
from medcat.utils.prepare_cdb import PrepareCDB
cat.cdb = preparator.prepare_csvs(['additional_concepts.csv'])

# ‚úÖ –ì–æ—Ç–æ–≤–æ –∑–∞ 3-4 –¥–Ω—ñ, F1 ‚âà 0.84
```

**–°—Ü–µ–Ω–∞—Ä—ñ–π –í: Custom entities + –≤–∏—Å–æ–∫—ñ –≤–∏–º–æ–≥–∏ –¥–æ —Ç–æ—á–Ω–æ—Å—Ç—ñ**
```python
# 1. –í–∏–∫–æ—Ä–∏—Å—Ç–∞—Ç–∏ zero-shot –¥–ª—è initial coverage
# 2. –ó—ñ–±—Ä–∞—Ç–∏ 50-100 annotated examples per entity type
# 3. Few-shot training –Ω–∞ Bio_ClinicalBERT –∞–±–æ MedCAT
# 4. Active learning loop –∑ MedCATtrainer

# ‚úÖ 2-4 —Ç–∏–∂–Ω—ñ, F1 ‚âà 0.85-0.92
```

### –í–∞–∂–ª–∏–≤—ñ –∑–∞—Å—Ç–µ—Ä–µ–∂–µ–Ω–Ω—è

**1. –ù–µ –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–π—Ç–µ cat.train() —è–∫—â–æ –Ω–µ —Ö–æ—á–µ—Ç–µ training:**
```python
# ‚ùå –ù–ï–ü–†–ê–í–ò–õ–¨–ù–û:
for doc in documents:
    _ = cat(doc)  # –Ø–∫—â–æ cat.train=True, —Ü–µ —Ç—Ä–µ–Ω—É—î –º–æ–¥–µ–ª—å!

# ‚úÖ –ü–†–ê–í–ò–õ–¨–ù–û:
cat.spacy_cat.train = False  # –û–ë–û–í'–Ø–ó–ö–û–í–û –≤—Å—Ç–∞–Ω–æ–≤–∏—Ç–∏
for doc in documents:
    entities = cat.get_entities(doc)  # –¢—ñ–ª—å–∫–∏ inference
```

**2. –ü–µ—Ä–µ–≤—ñ—Ä—è–π—Ç–µ —â–æ vocab=None —è–∫—â–æ –Ω–µ –ø–æ—Ç—Ä—ñ–±–µ–Ω training:**
```python
# Vocab –ø–æ—Ç—Ä—ñ–±–µ–Ω —Ç—ñ–ª—å–∫–∏ –¥–ª—è:
# - Spell checking optimization
# - Unsupervised training
# - Domain-specific word embeddings

cat = CAT(cdb=cdb, config=config, vocab=None)  # ‚úÖ –î–ª—è dictionary-only
```

**3. –ù–∞–ª–∞—à—Ç—É–π—Ç–µ config –¥–ª—è precision vs recall trade-off:**
```python
# High precision (–º–∞–ª–æ false positives):
cat.config.ner['min_name_len'] = 4  # –î–æ–≤—à—ñ —Ç–µ—Ä–º—ñ–Ω–∏
cat.config.general['spell_check'] = False  # –ë–µ–∑ fuzzy matching
cat.config.linking['prefer_primary_name'] = 0.8  # –¢—ñ–ª—å–∫–∏ primary names

# High recall (–∑–Ω–∞–π—Ç–∏ –≤—Å–µ –º–æ–∂–ª–∏–≤–µ):
cat.config.ner['min_name_len'] = 2  # –ö–æ—Ä–æ—Ç–∫—ñ —Ç–µ—Ä–º—ñ–Ω–∏ —Ç–µ–∂
cat.config.general['spell_check'] = True  # –ó fuzzy matching
cat.config.ner['try_reverse_word_order'] = True  # –†—ñ–∑–Ω–∏–π –ø–æ—Ä—è–¥–æ–∫ —Å–ª—ñ–≤
```

### –ß–µ–∫–ª–∏—Å—Ç –¥–ª—è deployment –±–µ–∑ training

- [ ] CSV –∑ –∫–æ–Ω—Ü–µ–ø—Ç–∞–º–∏ –≥–æ—Ç–æ–≤–∏–π (cui, name –æ–±–æ–≤'—è–∑–∫–æ–≤—ñ)
- [ ] CDB —Å—Ç–≤–æ—Ä–µ–Ω–æ —á–µ—Ä–µ–∑ prepare_csvs()
- [ ] spacy –º–æ–¥–µ–ª—å –≤—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ (en_core_web_md)
- [ ] cat.spacy_cat.train = False –≤—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ
- [ ] vocab=None –ø—Ä–∏ —ñ–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—ó CAT
- [ ] Config –Ω–∞–ª–∞—à—Ç–æ–≤–∞–Ω–æ (linking['always_calculate_similarity'] = False)
- [ ] –ü—Ä–æ—Ç–µ—Å—Ç–æ–≤–∞–Ω–æ –Ω–∞ sample text
- [ ] –í–∏–∑–Ω–∞—á–µ–Ω–æ acceptable performance threshold
- [ ] Stakeholders –∑–Ω–∞—é—Ç—å –ø—Ä–æ –æ–±–º–µ–∂–µ–Ω–Ω—è (no disambiguation)
- [ ] –ü–ª–∞–Ω –ø–æ–∫—Ä–∞—â–µ–Ω–Ω—è (–∫–æ–ª–∏ –¥–æ–¥–∞—Ç–∏ training)

---

## 9. –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ñ —ñ–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∏ —Ç–∞ –ø–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è

### –ö–æ–ª–∏ —Ä–æ–∑–≥–ª—è–Ω—É—Ç–∏ –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–∏ –¥–æ MedCAT

**CLAMP (Clinical Language Annotation, Modeling, and Processing):**
```
–ü–µ—Ä–µ–≤–∞–≥–∏:
- GUI interface (–ª–µ–≥—à–µ –¥–ª—è non-programmers)
- –í–±—É–¥–æ–≤–∞–Ω—ñ pipelines –¥–ª—è common tasks
- Ranked #1-2 —É i2b2/ShARe challenges
- F1 ‚âà 0.72 –±–µ–∑ extensive training

–ù–µ–¥–æ–ª—ñ–∫–∏:
- –ú–µ–Ω—à –≥–Ω—É—á–∫–∏–π –Ω—ñ–∂ MedCAT
- –°–ª–∞–±–∫—ñ—à–∏–π transfer learning
- GUI-focused (–º–µ–Ω—à–µ –¥–ª—è automation)

Use case: Clinical annotation projects –∑ GUI, less technical teams
```

**scispaCy:**
```
–ü–µ—Ä–µ–≤–∞–≥–∏:
- MIT license (–ø–æ–≤–Ω—ñ—Å—Ç—é open source)
- –õ–µ–≥–∫–∏–π —É –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—ñ
- –ë–∞–≥–∞—Ç–æ pretrained –º–æ–¥–µ–ª–µ–π
- –Ü–Ω—Ç–µ–≥—Ä–∞—Ü—ñ—è –∑ spaCy ecosystem

–ù–µ–¥–æ–ª—ñ–∫–∏:
- –ù–∏–∂—á–∞ F1 (0.60-0.65 vs 0.84 MedCAT pretrained)
- –û–±–º–µ–∂–µ–Ω—ñ entity types
- –°–ª–∞–±–∫—ñ—à–∞ –ø—ñ–¥—Ç—Ä–∏–º–∫–∞ custom ontologies

Use case: Open-source projects, quick prototyping, standard entities
```

**MetaMap:**
```
–ü–µ—Ä–µ–≤–∞–≥–∏:
- NLM official tool
- Comprehensive UMLS coverage
- No training needed

–ù–µ–¥–æ–ª—ñ–∫–∏:
- –ü–æ–≤—ñ–ª—å–Ω–∏–π
- –ù–∏–∂—á–∞ F1 –Ω–∞ —Å—É—á–∞—Å–Ω–∏—Ö benchmarks
- –û–±–º–µ–∂–µ–Ω–∏–π –¥–æ UMLS

Use case: Legacy systems, need for official NLM tool
```

### –ú–∞—Ç—Ä–∏—Ü—è –≤–∏–±–æ—Ä—É —ñ–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—É

| –ö—Ä–∏—Ç–µ—Ä—ñ–π | MedCAT | scispaCy | CLAMP | MetaMap |
|----------|--------|----------|-------|---------|
| **Custom ontology** | ‚úÖ‚úÖ‚úÖ Excellent | üü° Limited | ‚úÖ Good | ‚ùå UMLS only |
| **No training needed** | ‚úÖ W/ pretrained | ‚úÖ‚úÖ Yes | ‚úÖ Mostly | ‚úÖ‚úÖ Yes |
| **F1 score** | 0.84 (pretrained) | 0.60-0.65 | 0.72 | 0.63-0.69 |
| **License** | Elastic 2.0 | MIT | Free (research) | Free |
| **Ease of use** | üü° Medium | ‚úÖ‚úÖ Easy | ‚úÖ Easy (GUI) | üü° Medium |
| **Disambiguation** | ‚úÖ‚úÖ Excellent | üü° Limited | ‚úÖ Good | ‚úÖ Rule-based |

---

## 10. –í–∏—Å–Ω–æ–≤–∫–∏ —Ç–∞ —Ñ—ñ–Ω–∞–ª—å–Ω—ñ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ—ó

### –ö–ª—é—á–æ–≤—ñ –≤–∏—Å–Ω–æ–≤–∫–∏

1. **MedCAT –ú–û–ñ–ï –ø—Ä–∞—Ü—é–≤–∞—Ç–∏ –±–µ–∑ unsupervised training** –∑ dictionary-only –ø—ñ–¥—Ö–æ–¥–æ–º
2. **–ú—ñ–Ω—ñ–º–∞–ª—å–Ω—ñ –≤–∏–º–æ–≥–∏:** CDB + spacy model (vocab –æ–ø—Ü—ñ–æ–Ω–∞–ª—å–Ω–∏–π)
3. **Performance –±–µ–∑ training:** F1 ‚âà 0.638 (clinical), –Ω–∞ 20-25% –Ω–∏–∂—á–µ –Ω—ñ–∂ –∑ training
4. **–û—Å–Ω–æ–≤–Ω–µ –æ–±–º–µ–∂–µ–Ω–Ω—è:** Disambiguation –Ω–µ –ø—Ä–∞—Ü—é—î –¥–ª—è ambiguous concepts (~40% –∫–æ–Ω—Ü–µ–ø—Ç—ñ–≤)
5. **Pretrained –º–æ–¥–µ–ª—ñ** –≤–∏—Ä—ñ—à—É—é—Ç—å –±—ñ–ª—å—à—ñ—Å—Ç—å –ø—Ä–æ–±–ª–µ–º: F1 = 0.84 –±–µ–∑ –≤–ª–∞—Å–Ω–æ–≥–æ training
6. **Transfer learning** –¥—É–∂–µ –µ—Ñ–µ–∫—Ç–∏–≤–Ω–∏–π: –¥–æ–¥–∞—Ç–∏ –≤–ª–∞—Å–Ω—ñ –∫–æ–Ω—Ü–µ–ø—Ç–∏ –¥–æ pretrained –º–æ–¥–µ–ª—ñ

### –†–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞–Ω–∞ —Å—Ç—Ä–∞—Ç–µ–≥—ñ—è –¥–ª—è –≤–∞—à–æ–≥–æ use case

**–Ø–∫—â–æ –≤–∞—à–∞ –æ–Ω—Ç–æ–ª–æ–≥—ñ—è –º–∞—î –ø–µ—Ä–µ–≤–∞–∂–Ω–æ —É–Ω—ñ–∫–∞–ª—å–Ω—ñ –Ω–∞–∑–≤–∏ (–º–∞–ª–æ ambiguity):**
```
‚Üí Dictionary-only MedCAT ‚úÖ
‚Üí –û—á—ñ–∫—É–≤–∞–Ω–∞ performance: F1 ‚âà 0.70-0.75
‚Üí –ß–∞—Å —Ä–æ–∑–≥–æ—Ä—Ç–∞–Ω–Ω—è: 1-2 –¥–Ω—ñ
‚Üí –ë–µ–∑ unsupervised training
```

**–Ø–∫—â–æ —î —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ñ –º–µ–¥–∏—á–Ω—ñ –∫–æ–Ω—Ü–µ–ø—Ç–∏ (UMLS/SNOMED overlap):**
```
‚Üí Pretrained MedCAT + –¥–æ–¥–∞—Ç–∏ –≤–ª–∞—Å–Ω—ñ –∫–æ–Ω—Ü–µ–ø—Ç–∏ ‚úÖ‚úÖ
‚Üí –û—á—ñ–∫—É–≤–∞–Ω–∞ performance: F1 ‚âà 0.84-0.88
‚Üí –ß–∞—Å —Ä–æ–∑–≥–æ—Ä—Ç–∞–Ω–Ω—è: 3-5 –¥–Ω—ñ–≤ (UMLS license + integration)
‚Üí –ú—ñ–Ω—ñ–º–∞–ª—å–Ω–∏–π self-supervised training –æ–ø—Ü—ñ–æ–Ω–∞–ª—å–Ω–æ (+0.05 F1)
```

**–Ø–∫—â–æ –ø–æ—Ç—Ä—ñ–±–Ω–∞ –≤–∏—Å–æ–∫–∞ —Ç–æ—á–Ω—ñ—Å—Ç—å —ñ —î ambiguous —Ç–µ—Ä–º—ñ–Ω–∏:**
```
‚Üí Pretrained MedCAT + domain self-supervised + supervised ‚úÖ‚úÖ‚úÖ
‚Üí –û—á—ñ–∫—É–≤–∞–Ω–∞ performance: F1 ‚âà 0.92-0.95
‚Üí –ß–∞—Å —Ä–æ–∑–≥–æ—Ä—Ç–∞–Ω–Ω—è: 3-6 —Ç–∏–∂–Ω—ñ–≤
‚Üí Unsupervised training –æ–±–æ–≤'—è–∑–∫–æ–≤–∏–π
```

### –ü—Ä–∞–∫—Ç–∏—á–Ω–∏–π –ø–ª–∞–Ω –¥—ñ–π –¥–ª—è –≤–∞—à–æ—ó —Å–∏—Ç—É–∞—Ü—ñ—ó

**–§–∞–∑–∞ 1: Immediate deployment (–¢–∏–∂–¥–µ–Ω—å 1)**
```python
# –°—Ç–≤–æ—Ä–∏—Ç–∏ CDB –∑ –≤–∞—à–æ—ó –æ–Ω—Ç–æ–ª–æ–≥—ñ—ó
from medcat.cdb_maker import CDBMaker
cdb = CDBMaker(config).prepare_csvs(['your_ontology.csv'])

# –Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑—É–≤–∞—Ç–∏ CAT –ë–ï–ó training
cat = CAT(cdb=cdb, config=config, vocab=None)
cat.spacy_cat.train = False

# –ü—Ä–æ—Ç–µ—Å—Ç—É–≤–∞—Ç–∏ –Ω–∞ sample data
# –û—Ü—ñ–Ω–∏—Ç–∏ performance: —è–∫—â–æ F1 > 0.70 ‚Üí –≥–æ—Ç–æ–≤–æ –¥–æ use!
```

**–§–∞–∑–∞ 2: –ü–æ–∫—Ä–∞—â–µ–Ω–Ω—è (—è–∫—â–æ –ø–æ—Ç—Ä—ñ–±–Ω–æ, –¢–∏–∂–¥–µ–Ω—å 2-3)**
```python
# –û–ø—Ü—ñ—è –ê: –î–æ–¥–∞—Ç–∏ pretrained embeddings (—è–∫—â–æ —î UMLS license)
cat = CAT.load_model_pack('umls_small.zip')
# –î–æ–¥–∞—Ç–∏ –≤–ª–∞—Å–Ω—ñ –∫–æ–Ω—Ü–µ–ø—Ç–∏ –¥–æ cat.cdb

# –û–ø—Ü—ñ—è –ë: Short self-supervised training (—è–∫—â–æ —î 10K+ docs)
cat.train = True
for doc in your_corpus[:10000]:
    _ = cat(doc)
cat.train = False
# –û—á—ñ–∫—É–≤–∞–Ω–µ –ø–æ–∫—Ä–∞—â–µ–Ω–Ω—è: +0.05-0.10 F1
```

**–§–∞–∑–∞ 3: –û–ø—Ç–∏–º—ñ–∑–∞—Ü—ñ—è (—è–∫—â–æ –ø–æ—Ç—Ä—ñ–±–Ω–æ, –ú—ñ—Å—è—Ü—å 2+)**
```python
# –í–∏–∫–æ—Ä–∏—Å—Ç–∞—Ç–∏ MedCATtrainer –¥–ª—è supervised learning
# –ó—ñ–±—Ä–∞—Ç–∏ 500-1000 annotated examples
# Active learning loop
# –î–æ—Å—è–≥—Ç–∏ F1 > 0.90
```

### –û—Å—Ç–∞—Ç–æ—á–Ω–∞ –≤—ñ–¥–ø–æ–≤—ñ–¥—å –Ω–∞ –≤–∞—à–µ –ø–∏—Ç–∞–Ω–Ω—è

**–¢–ê–ö, –º–æ–∂–Ω–∞ —ñ–Ω—Ç–µ–≥—Ä—É–≤–∞—Ç–∏ –≤–ª–∞—Å–Ω—É –º–µ–¥–∏—á–Ω—É –æ–Ω—Ç–æ–ª–æ–≥—ñ—é –≤ MedCAT –ë–ï–ó unsupervised training:**

‚úÖ –°—Ç–≤–æ—Ä–∏—Ç–∏ CDB –∑ CSV (–≤–∞—à—ñ –∫–ª–∞—Å—Ç–µ—Ä–∏, keywords, patterns)  
‚úÖ –í–∏–∫–æ—Ä–∏—Å—Ç–∞—Ç–∏ en_core_web_md –∞–±–æ en_core_sci_md –Ω–∞–ø—Ä—è–º—É  
‚úÖ Vocab –ù–ï –ø–æ—Ç—Ä—ñ–±–µ–Ω (–º–æ–∂–Ω–∞ vocab=None)  
‚úÖ –°–∏—Å—Ç–µ–º–∞ –ø—Ä–∞—Ü—é—î –≤ dictionary-matching —Ä–µ–∂–∏–º—ñ  
‚úÖ –û—á—ñ–∫—É–≤–∞–Ω–∞ performance: F1 ‚âà 0.60-0.75 –∑–∞–ª–µ–∂–Ω–æ –≤—ñ–¥ ambiguity  

**–û—Å–Ω–æ–≤–Ω—ñ –æ–±–º–µ–∂–µ–Ω–Ω—è:**
‚ùå Disambiguation –Ω–µ –ø—Ä–∞—Ü—é—î (ambiguous names)  
‚ùå Confidence scoring –æ–±–º–µ–∂–µ–Ω–∏–π  
‚ùå Performance –Ω–∞ 20-25% –Ω–∏–∂—á–µ –Ω—ñ–∂ –∑ training  

**–ù–∞–π–∫—Ä–∞—â–∞ –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–∞:**
üéØ –í–∏–∫–æ—Ä–∏—Å—Ç–∞—Ç–∏ pretrained MedCAT –º–æ–¥–µ–ª—å (UMLS/SNOMED) + –¥–æ–¥–∞—Ç–∏ –≤–ª–∞—Å–Ω—ñ –∫–æ–Ω—Ü–µ–ø—Ç–∏ ‚Üí F1 ‚âà 0.84 –ë–ï–ó –≤–ª–∞—Å–Ω–æ–≥–æ unsupervised training

---

## –î–æ–¥–∞—Ç–∫–æ–≤—ñ —Ä–µ—Å—É—Ä—Å–∏

**–û—Ñ—ñ—Ü—ñ–π–Ω–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü—ñ—è:**
- MedCAT GitHub: https://github.com/CogStack/MedCAT
- MedCAT Docs: https://medcat.readthedocs.io/
- Model Downloads: https://medcat.sites.er.kcl.ac.uk/auth-callback

**Pretrained Resources:**
- BioWordVec: https://github.com/ncbi-nlp/BioWordVec
- Bio_ClinicalBERT: https://huggingface.co/emilyalsentzer/Bio_ClinicalBERT
- scispaCy: https://allenai.github.io/scispacy/
- UMLS License: https://uts.nlm.nih.gov/

**–ö–æ—Ä–∏—Å–Ω—ñ —Å—Ç–∞—Ç—Ç—ñ:**
- "Multi-domain Clinical NLP with MedCAT" (Kraljevic et al., 2021)
- "MedCAT | Extracting Diseases from EHRs" (Medium)
- MedCAT Tutorials: https://github.com/CogStack/MedCATtutorials

**Community:**
- CogStack Discourse: https://discourse.cogstack.org/
- GitHub Issues: https://github.com/CogStack/MedCAT/issues